{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#install the necessary dependencies by uncommenting and running the following commands:\n",
    "#!wget https://raw.githubusercontent.com/bespoke-inc/bespoke-public-talks/2020/2020-10-31-ScipyJapan-Regex-to-DL/requirements.txt\n",
    "#!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task #1: Create a corpus\n",
    "\n",
    "The first task will be making your own training data based on the above format. We will work a small dataset that we've provided and later some publicly available ones but participants are expected to create their own for this part of the workshop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Data\n",
    "This is a sample format of the training data we want to use:\n",
    "\n",
    "```\n",
    "training_phrases = {\n",
    "        'when_is_check_in' : ['when is check-in','When can I check in?','when's checkin'],\n",
    "        'where_is_the_front_desk' : ['Where is the front desk?','what is the location of the front desk?'...]}\n",
    "}\n",
    "\n",
    "answers : {\n",
    "        'when_is_check_in' : 'Check in is at 3pm! :)',\n",
    "        'where_is_the_front_desk' : 'The front desk is located on the 2nd floor.'}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-10-30 11:59:31--  https://raw.githubusercontent.com/bespoke-inc/bespoke-public-talks/master/2020/2020-08-22-MLT-Rules-to-DL/training_sample.json\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 16736 (16K) [text/plain]\n",
      "Saving to: ‘training_sample.json’\n",
      "\n",
      "training_sample.jso 100%[===================>]  16.34K  --.-KB/s    in 0.02s   \n",
      "\n",
      "2020-10-30 11:59:31 (821 KB/s) - ‘training_sample.json’ saved [16736/16736]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#get sample training data\n",
    "!wget https://raw.githubusercontent.com/bespoke-inc/bespoke-public-talks/master/2020/2020-08-22-MLT-Rules-to-DL/training_sample.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = json.load(open('./training_sample.json','r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hotel.when_is_check_in',\n",
       " 'hotel.when_is_check_out',\n",
       " 'hotel.is_there_early_check_in',\n",
       " 'hotel.is_there_late_check_out',\n",
       " 'hotel.where_is_the_front_desk_located']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(training_data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = {\n",
    "    'hotel.when_is_check_in': 'Check in is at 3pm!',\n",
    "    'hotel.when_is_check_out': 'Check out is at 10am!',\n",
    "    'hotel.is_there_late_check_out': 'For early check-out or late check-in please schedule beforehand',\n",
    "    'hotel.is_there_early_check_in': 'For early check-out or late check-in please schedule beforehand',\n",
    "    'hotel.where_is_the_front_desk_located': 'Front desk is located on the 2nd floor'\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "punct_re_escape = re.compile('[%s]' % re.escape('!\"#$%&()*+,./:;<=>?@[\\\\]^_`{|}~'))\n",
    "\n",
    "class MyChatbotData:\n",
    "    \n",
    "    def __init__(self, json_obj, text_fld, answers):\n",
    "        dfs = []\n",
    "        for i, (intent, data) in enumerate(json_obj.items()):\n",
    "            # lowercase and remove punctuation\n",
    "            patterns = data[text_fld].copy()\n",
    "            for i, p in enumerate(patterns):\n",
    "                p = p.lower()\n",
    "                p = self.remove_punctuation(p)\n",
    "                patterns[i] = p\n",
    "                answer = answers[intent]\n",
    "            df = pd.DataFrame(list(zip([intent]*len(patterns), patterns, [answer]*len(patterns))), \\\n",
    "                              columns=['intent', 'phrase', 'answer'])\n",
    "            dfs.append(df)\n",
    "        self.df = pd.concat(dfs)\n",
    "    \n",
    "    def get_answer(self, intent):\n",
    "        return pd.unique(self.df[self.df['intent'] == intent]['answer'])[0]\n",
    "    \n",
    "    def remove_punctuation(self, text):\n",
    "        return punct_re_escape.sub('', text)\n",
    "    \n",
    "    def get_phrases(self, intent):\n",
    "        return list(self.df[self.df['intent'] == intent]['phrase'])\n",
    "    \n",
    "    def get_intents(self):\n",
    "        return list(pd.unique(self.df['intent']))\n",
    "    \n",
    "    def show_batch(self, size=5):\n",
    "        return self.df.head(size)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbot_data = MyChatbotData(training_data, 'patterns', answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intent</th>\n",
       "      <th>phrase</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hotel.when_is_check_in</td>\n",
       "      <td>when is check-in</td>\n",
       "      <td>Check in is at 3pm!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hotel.when_is_check_in</td>\n",
       "      <td>how to check in</td>\n",
       "      <td>Check in is at 3pm!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hotel.when_is_check_in</td>\n",
       "      <td>what time is the latest we can check into the ...</td>\n",
       "      <td>Check in is at 3pm!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hotel.when_is_check_in</td>\n",
       "      <td>what time is check in open till</td>\n",
       "      <td>Check in is at 3pm!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hotel.when_is_check_in</td>\n",
       "      <td>can you advise the check in time</td>\n",
       "      <td>Check in is at 3pm!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>hotel.when_is_check_in</td>\n",
       "      <td>what time is check in for new hotel otani toky...</td>\n",
       "      <td>Check in is at 3pm!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>hotel.when_is_check_in</td>\n",
       "      <td>late check in</td>\n",
       "      <td>Check in is at 3pm!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>hotel.when_is_check_in</td>\n",
       "      <td>can i check in late</td>\n",
       "      <td>Check in is at 3pm!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>hotel.when_is_check_in</td>\n",
       "      <td>what about check in</td>\n",
       "      <td>Check in is at 3pm!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>hotel.when_is_check_in</td>\n",
       "      <td>im down to check in</td>\n",
       "      <td>Check in is at 3pm!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   intent                                             phrase  \\\n",
       "0  hotel.when_is_check_in                                   when is check-in   \n",
       "1  hotel.when_is_check_in                                    how to check in   \n",
       "2  hotel.when_is_check_in  what time is the latest we can check into the ...   \n",
       "3  hotel.when_is_check_in                    what time is check in open till   \n",
       "4  hotel.when_is_check_in                   can you advise the check in time   \n",
       "5  hotel.when_is_check_in  what time is check in for new hotel otani toky...   \n",
       "6  hotel.when_is_check_in                                      late check in   \n",
       "7  hotel.when_is_check_in                                can i check in late   \n",
       "8  hotel.when_is_check_in                                what about check in   \n",
       "9  hotel.when_is_check_in                                im down to check in   \n",
       "\n",
       "                answer  \n",
       "0  Check in is at 3pm!  \n",
       "1  Check in is at 3pm!  \n",
       "2  Check in is at 3pm!  \n",
       "3  Check in is at 3pm!  \n",
       "4  Check in is at 3pm!  \n",
       "5  Check in is at 3pm!  \n",
       "6  Check in is at 3pm!  \n",
       "7  Check in is at 3pm!  \n",
       "8  Check in is at 3pm!  \n",
       "9  Check in is at 3pm!  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbot_data.show_batch(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "368"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chatbot_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rule-based intent ~~classification~~ matching\n",
    "\n",
    "The simplest approach to find if an query falls into a certain intent is to do some string comparison with our dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNK = \"I don't know\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exact_match(query):\n",
    "    intents = chatbot_data.get_intents()\n",
    "    for i in intents:\n",
    "        phrases = chatbot_data.get_phrases(i)\n",
    "        if query in phrases:\n",
    "            return chatbot_data.get_answer(i)\n",
    "    return UNK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'For early check-out or late check-in please schedule beforehand'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exact_match(\"is there early check-in\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Check in is at 3pm!'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exact_match(\"when do i check in\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I don't know\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exact_match(\"can i check-in earlier than 12pm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "- CJK\n",
    "- normalize contractions\n",
    "- remove hyphens\n",
    "- remove stopwords\n",
    "- check for typos\n",
    "- normalize plurals\n",
    "- normalize ascii\n",
    "- normalize emojis\n",
    "- remove punctuation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "EMOJIS = [[':)', '😀'],[';)', '😉'],[':(', '😞'],[';((', '😢'],[':p', '😛']]\n",
    "_emoji_re = '[\\U00010000-\\U0010ffff]+'\n",
    "emoji_re = re.compile(_emoji_re, flags=re.UNICODE)\n",
    "\n",
    "def emoji_normalize(text):\n",
    "    for e1, e2 in EMOJIS:\n",
    "        text = text.replace(e1, e2)\n",
    "    return text\n",
    "\n",
    "def is_emoji(text):\n",
    "    emoji = \"\".join(re.findall(_emoji_re, text))\n",
    "    return emoji == text\n",
    "\n",
    "def emoji_isolate(text):\n",
    "    EMJ = \"__EMOJI__\"\n",
    "    emoji_list = re.findall(_emoji_re, text)\n",
    "    text = emoji_re.sub(f\" {EMJ} \", text)\n",
    "    new_str, ctr = [], 0\n",
    "    for tok in text.split():\n",
    "        if tok == EMJ:\n",
    "            new_str.append(emoji_list[ctr])\n",
    "            ctr += 1\n",
    "        else:\n",
    "            new_str.append(tok)\n",
    "    return \" \".join(new_str).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "\n",
    "def ascii_normalize(text):\n",
    "    return unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode(\"utf-8\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "punct_re_escape = re.compile('[%s]' % re.escape('!\"#$%&()*+,./:;<=>?@[\\\\]^_`{|}~'))\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    punct_re_escape.sub('', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    text = ascii_normalize(text) or text\n",
    "    text = emoji_normalize(text) or text\n",
    "    text = emoji_isolate(text) or text\n",
    "    text = remove_punctuation(text) or text\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partial String Matching\n",
    "Instead of checking is the entire query string exists in our dataset, we try to find a partial match\n",
    "and pick the intent that matches most closely. We will try to do this with using Levenshtein Distance \n",
    "to calculate the differences between sequences. The library [fuzzywuzzy](https://github.com/seatgeek/fuzzywuzzy)\n",
    "can help us do this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fuzzywuzzy\n",
      "  Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl (18 kB)\n",
      "Installing collected packages: fuzzywuzzy\n",
      "Successfully installed fuzzywuzzy-0.18.0\n",
      "\u001b[33mWARNING: You are using pip version 20.2.2; however, version 20.2.4 is available.\n",
      "You should consider upgrading via the '/Users/asirsaeed/projects/dev/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install fuzzywuzzy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzywuzzy import process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fuzzy_matching(query):\n",
    "    intents = chatbot_data.get_intents()\n",
    "    for i in intents:\n",
    "        phrases = chatbot_data.get_phrases(i)\n",
    "        match, score = process.extractOne(query, phrases)\n",
    "        if score > 90:\n",
    "            return chatbot_data.get_answer(i)\n",
    "    return UNK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Check in is at 3pm!'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fuzzy_matching(\"when do i check-in\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'For early check-out or late check-in please schedule beforehand'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fuzzy_matching(\"can i check-in earlier than 12pm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Check in is at 3pm!'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fuzzy_matching(\"what time is early check-in\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML Classification\n",
    "We will now add a probabilistic classifier to our set of methods to get better intent classification.\n",
    "The algorithm we will use is [naive bayes](https://scikit-learn.org/stable/modules/naive_bayes.html)\n",
    "\n",
    "Naive Bayes classifiers works quite well for small amount of training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizer\n",
    "Before we feed it to our model for training we need to tokenize our training instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm',parse=False,tagger=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['when', 'can', 'i', 'check', 'in', '?']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(\"when can i check in?\")\n",
    "[tok.text for tok in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['when', 'can', 'i', 'check', '-', 'in', '?']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(\"when can i check-in?\")\n",
    "[tok.text for tok in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'did', \"n't\"]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(\"i didn't\")\n",
    "[tok.text for tok in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['thank', 'you', 'ありがとう']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(\"thank you ありがとう\")\n",
    "[tok.text for tok in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['did', \"n't\", 'could', \"n't\"]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(\"didn't    couldn't   \")\n",
    "[tok.text for tok in doc if tok.text.strip()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/asirsaeed/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopwords = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_nd_join(text):\n",
    "    doc = nlp(text.lower())\n",
    "    return \" \".join(tok.text for tok in doc if tok.text.strip() not in stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_xs_ys(train_data):\n",
    "    x, y = [], []\n",
    "    intents = chatbot_data.get_intents()\n",
    "    for i in intents:\n",
    "        phrases = chatbot_data.get_phrases(i)\n",
    "        x += [tokenize_nd_join(phrase) for phrase in phrases]\n",
    "        y += [i]*len(phrases)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(x,y):\n",
    "    vect = CountVectorizer(ngram_range=(1,2),max_features=None)\n",
    "    nb = Pipeline([('vect',vect),('clf',ComplementNB(alpha=1.0,norm=False))])\n",
    "    nb.fit(x,y)\n",
    "    return nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = get_xs_ys(training_data)\n",
    "nb_model = train(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nb_pred(query):\n",
    "    tokenized_query = tokenize_nd_join(query)\n",
    "    pred = nb_model.predict([tokenized_query])[0]\n",
    "    return chatbot_data.get_answer(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'For early check-out or late check-in please schedule beforehand'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_pred(\"what time is early check-in\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nb_pred_top3(query):\n",
    "    tokenized_query = tokenize_nd_join(query)\n",
    "    pred_prob = nb_model.predict_proba([tokenized_query])\n",
    "    preds_sorted = np.argsort(pred_prob)\n",
    "    top3 = preds_sorted[:,-1],preds_sorted[:,-2],preds_sorted[:,-2]\n",
    "    if pred_prob[0,top3[0]] > (pred_prob[0,top3[1]] + pred_prob[0,top3[2]]):\n",
    "        pred = nb_model.named_steps['clf'].classes_[top3[0]][0]\n",
    "        return chatbot_data.get_answer(pred)\n",
    "    return UNK\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'For early check-out or late check-in please schedule beforehand'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_pred_top3(\"is there early check-in\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intent Classification Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pred(query):\n",
    "    query = query.lower()\n",
    "    pred = exact_match(query)\n",
    "    if pred == UNK: pred = exact_match(preprocess(query))\n",
    "    if pred == UNK: pred = nb_pred_top3(query)\n",
    "    if pred == UNK: pred = nb_pred_top3(preprocess(query))\n",
    "    if pred == UNK: pred = fuzzy_matching(query)\n",
    "    if pred == UNK: pred = fuzzy_matching(preprocess(query))\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Check in is at 3pm!'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_pred(\"when is check-in\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'For early check-out or late check-in please schedule beforehand'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_pred(\"can i check-out late?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Front desk is located on the 2nd floor'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_pred(\"where can i find the front desk?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moving ML to DL\n",
    "We see that this pipeline using some rules and a probabilistic model are working quite well.\n",
    "However, it doesn't scale with data and requires adding a lot of preprocessing and nuances to get working properly\n",
    "\n",
    "Pros:\n",
    "- There are noticeable improvement in using NNs over the current probabilistic model.\n",
    "- Model can scale with data i.e it can improve as we add more annotated training data\n",
    "- This can be a good point to move to NNs, since we are reaching the limits of rule based systems e.g fewer engineered features\n",
    "- Simplified pipeline\n",
    "\n",
    "Cons:\n",
    "- Huge gains cannot be seen until the data is cleaned. \n",
    "- In its current state, the model will either be the same or slightly better than the current approach.\n",
    "- Infrastructure changes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification with Distil Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai import *\n",
    "from fastai.text import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = {\n",
    "    'hotel.when_is_check_in': 'Check in is at 3pm!',\n",
    "    'hotel.when_is_check_out': 'Check out is at 10am!',\n",
    "    'hotel.is_there_late_check_out': 'For early check-out or late check-in please schedule beforehand',\n",
    "    'hotel.is_there_early_check_in': 'For early check-out or late check-in please schedule beforehand',\n",
    "    'hotel.where_is_the_front_desk_located': 'Front desk is located on the 2nd floor'\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyChatbotData:\n",
    "    \n",
    "    def __init__(self, json_obj, text_fld, answers):\n",
    "        dfs = []\n",
    "        for i, (intent, data) in enumerate(json_obj.items()):\n",
    "            # lowercase and remove punctuation\n",
    "            patterns = data[text_fld].copy()\n",
    "            for i, p in enumerate(patterns):\n",
    "                p = p.lower()\n",
    "                p = self.remove_punctuation(p)\n",
    "                patterns[i] = p\n",
    "                answer = answers[intent]\n",
    "            df = pd.DataFrame(list(zip([intent]*len(patterns), patterns, [answer]*len(patterns))), \\\n",
    "                              columns=['intent', 'phrase', 'answer'])\n",
    "            dfs.append(df)\n",
    "        self.df = pd.concat(dfs)\n",
    "    \n",
    "    def get_answer(self, intent):\n",
    "        return pd.unique(self.df[self.df['intent'] == intent]['answer'])[0]\n",
    "    \n",
    "    def remove_punctuation(self, text):\n",
    "        return punct_re_escape.sub('', text)\n",
    "    \n",
    "    def get_phrases(self, intent):\n",
    "        return list(self.df[self.df['intent'] == intent]['phrase'])\n",
    "    \n",
    "    def get_intents(self):\n",
    "        return list(pd.unique(self.df['intent']))\n",
    "    \n",
    "    def show_batch(self, size=5):\n",
    "        return self.df.head(size)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = json.load(open('./training_sample.json','r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hotel.when_is_check_in',\n",
       " 'hotel.when_is_check_out',\n",
       " 'hotel.is_there_early_check_in',\n",
       " 'hotel.is_there_late_check_out',\n",
       " 'hotel.where_is_the_front_desk_located']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(training_data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbot_data = MyChatbotData(training_data, 'patterns', answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intent</th>\n",
       "      <th>phrase</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hotel.when_is_check_in</td>\n",
       "      <td>when is check-in</td>\n",
       "      <td>Check in is at 3pm!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hotel.when_is_check_in</td>\n",
       "      <td>how to check in</td>\n",
       "      <td>Check in is at 3pm!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hotel.when_is_check_in</td>\n",
       "      <td>what time is the latest we can check into the ...</td>\n",
       "      <td>Check in is at 3pm!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hotel.when_is_check_in</td>\n",
       "      <td>what time is check in open till</td>\n",
       "      <td>Check in is at 3pm!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hotel.when_is_check_in</td>\n",
       "      <td>can you advise the check in time</td>\n",
       "      <td>Check in is at 3pm!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   intent                                             phrase  \\\n",
       "0  hotel.when_is_check_in                                   when is check-in   \n",
       "1  hotel.when_is_check_in                                    how to check in   \n",
       "2  hotel.when_is_check_in  what time is the latest we can check into the ...   \n",
       "3  hotel.when_is_check_in                    what time is check in open till   \n",
       "4  hotel.when_is_check_in                   can you advise the check in time   \n",
       "\n",
       "                answer  \n",
       "0  Check in is at 3pm!  \n",
       "1  Check in is at 3pm!  \n",
       "2  Check in is at 3pm!  \n",
       "3  Check in is at 3pm!  \n",
       "4  Check in is at 3pm!  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = chatbot_data.df\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 368)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(df['intent'])), len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('./')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adapting fastai code for training transformers was inspired from this [blog post](https://towardsdatascience.com/fastai-with-transformers-bert-roberta-xlnet-xlm-distilbert-4f41ee18ecb2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertForSequenceClassification, DistilBertTokenizer, DistilBertConfig\n",
    "from transformers import PreTrainedTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformersBaseTokenizer(BaseTokenizer):\n",
    "    def __init__(self, pretrained_tokenizer: PreTrainedTokenizer, model_type = 'bert', **kwargs):\n",
    "        self._pretrained_tokenizer = pretrained_tokenizer\n",
    "        self.max_seq_len = pretrained_tokenizer.max_len\n",
    "        self.model_type = model_type\n",
    "\n",
    "    def __call__(self, *args, **kwargs): \n",
    "        return self\n",
    "\n",
    "    def tokenizer(self, t:str) -> List[str]:\n",
    "        CLS = self._pretrained_tokenizer.cls_token\n",
    "        SEP = self._pretrained_tokenizer.sep_token\n",
    "        tokens = [CLS] + self._pretrained_tokenizer.tokenize(t)[:self.max_seq_len - 2] + [SEP]\n",
    "        return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "transformer_base_tokenizer = TransformersBaseTokenizer(pretrained_tokenizer = transformer_tokenizer, model_type = model_type)\n",
    "fastai_tokenizer = Tokenizer(tok_func = transformer_base_tokenizer, pre_rules=[], post_rules=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformersVocab(Vocab):\n",
    "    def __init__(self, tokenizer: PreTrainedTokenizer):\n",
    "        super(TransformersVocab, self).__init__(itos = [])\n",
    "        self.tokenizer = tokenizer\n",
    "    \n",
    "    def numericalize(self, t:Collection[str]) -> List[int]:\n",
    "        \"Convert a list of tokens `t` to their ids.\"\n",
    "        return self.tokenizer.convert_tokens_to_ids(t)\n",
    "\n",
    "    def textify(self, nums:Collection[int], sep=' ') -> List[str]:\n",
    "        \"Convert a list of `nums` to their tokens.\"\n",
    "        nums = np.array(nums).tolist()\n",
    "        return sep.join(self.tokenizer.convert_ids_to_tokens(nums)) if sep is not None else self.tokenizer.convert_ids_to_tokens(nums)\n",
    "        \n",
    "    def __getstate__(self):\n",
    "        return {'itos':self.itos, 'tokenizer':self.tokenizer}\n",
    "\n",
    "    def __setstate__(self, state:dict):\n",
    "        self.itos = state['itos']\n",
    "        self.tokenizer = state['tokenizer']\n",
    "        self.stoi = collections.defaultdict(int,{v:k for k,v in enumerate(self.itos)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_vocab =  TransformersVocab(tokenizer = transformer_tokenizer)\n",
    "numericalize_processor = NumericalizeProcessor(vocab=transformer_vocab)\n",
    "\n",
    "tokenize_processor = TokenizeProcessor(tokenizer=fastai_tokenizer, \n",
    "                                       include_bos=False, \n",
    "                                       include_eos=False)\n",
    "\n",
    "transformer_processor = [tokenize_processor, numericalize_processor]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pad_idx = transformer_tokenizer.pad_token_id\n",
    "\n",
    "databunch = (TextList.from_df(df, cols='phrase', processor=transformer_processor)\n",
    "             .split_by_rand_pct()\n",
    "             .label_from_df(cols= 'intent')\n",
    "             .databunch(bs=64, pad_first=False, pad_idx=pad_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerModel(nn.Module):\n",
    "  \n",
    "    def __init__(self, transformer):\n",
    "        super(TransformerModel,self).__init__()\n",
    "        self.transformer = transformer\n",
    "        \n",
    "    def forward(self, input_ids):\n",
    "        # Return only the logits from the transfomer\n",
    "        logits = self.transformer(input_ids)[0]   \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = DistilBertConfig.from_pretrained('distilbert-base-uncased')\n",
    "config.num_labels = databunch.train_ds.c\n",
    "\n",
    "distil_bert = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', config=config)\n",
    "transformer_model = TransformerModel(distil_bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AdamW\n",
    "from functools import partial\n",
    "\n",
    "CustomAdamW = partial(AdamW, correct_bias=False)\n",
    "\n",
    "learn = Learner(databunch, transformer_model, opt_func = CustomAdamW, metrics=[accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "list_layers = [learn.model.transformer.base_model.embeddings,\n",
    "               learn.model.transformer.base_model.transformer.layer[0],\n",
    "               learn.model.transformer.base_model.transformer.layer[1],\n",
    "               learn.model.transformer.base_model.transformer.layer[2],\n",
    "               learn.model.transformer.base_model.transformer.layer[3],\n",
    "               learn.model.transformer.base_model.transformer.layer[4],\n",
    "               learn.model.transformer.base_model.transformer.layer[5],\n",
    "               learn.model.transformer.pre_classifier,\n",
    "               learn.model.transformer.classifier]\n",
    "               \n",
    "learn.split(list_layers);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.freeze_to(-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='21' class='' max='25' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      84.00% [21/25 00:34<00:06]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.631550</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.634111</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.635967</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.635991</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.632920</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.631142</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.626869</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.619058</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.610793</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.598671</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.583405</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.556554</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.508474</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1.485715</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1.507267</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.514580</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>2.262949</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>3.270256</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>3.854247</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>3.688505</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>3.490579</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='2' class='' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      50.00% [2/4 00:01<00:01 3.4864]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.lr_find()\n",
    "learn.recorder.plot(skip_end=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.659371</td>\n",
       "      <td>1.850191</td>\n",
       "      <td>0.219178</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.582303</td>\n",
       "      <td>1.291429</td>\n",
       "      <td>0.438356</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.478284</td>\n",
       "      <td>1.276817</td>\n",
       "      <td>0.561644</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(3,max_lr=1e-3,moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.359964</td>\n",
       "      <td>21.788212</td>\n",
       "      <td>0.232877</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>5.632231</td>\n",
       "      <td>2.840953</td>\n",
       "      <td>0.315068</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.freeze_to(-3)\n",
    "learn.fit_one_cycle(2, slice(8e-4/(2.6**4),8e-4), moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4.328775</td>\n",
       "      <td>4.122964</td>\n",
       "      <td>0.219178</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.377215</td>\n",
       "      <td>1.870122</td>\n",
       "      <td>0.315068</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.freeze_to(-5)\n",
    "learn.fit_one_cycle(2, slice(5e-4/(2.6**4),5e-4), moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.787705</td>\n",
       "      <td>1.675999</td>\n",
       "      <td>0.082192</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.670295</td>\n",
       "      <td>1.274541</td>\n",
       "      <td>0.520548</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.freeze_to(-8)\n",
    "learn.fit_one_cycle(2, slice(3e-4/(2.6**4),3e-4), moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.350474</td>\n",
       "      <td>1.114394</td>\n",
       "      <td>0.520548</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.236143</td>\n",
       "      <td>0.773349</td>\n",
       "      <td>0.684932</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.115984</td>\n",
       "      <td>0.634548</td>\n",
       "      <td>0.808219</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.991540</td>\n",
       "      <td>0.543521</td>\n",
       "      <td>0.808219</td>\n",
       "      <td>00:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.896839</td>\n",
       "      <td>0.515857</td>\n",
       "      <td>0.849315</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(5, slice(1e-4/(2.6**4),1e-4), moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hotel.is_there_late_check_out tensor([0.0371, 0.4484, 0.2567, 0.2468, 0.0111])\n"
     ]
    }
   ],
   "source": [
    "pred, _, probs = learn.predict(\"what time is check-in?\")\n",
    "print(learn.data.train_ds.y.classes[pred.data], probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "interp = TextClassificationInterpretation(learn,*learn.get_preds(with_loss=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Text</th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Actual</th>\n",
       "      <th>Loss</th>\n",
       "      <th>Probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>[CLS] can i check ##out late [SEP]</td>\n",
       "      <td>hotel.is_there_early_check_in</td>\n",
       "      <td>hotel.is_there_late_check_out</td>\n",
       "      <td>4.09</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>[CLS] how to check in [SEP]</td>\n",
       "      <td>hotel.where_is_the_front_desk_located</td>\n",
       "      <td>hotel.when_is_check_in</td>\n",
       "      <td>2.58</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>[CLS] when is the usual check - in time [SEP]</td>\n",
       "      <td>hotel.is_there_late_check_out</td>\n",
       "      <td>hotel.when_is_check_in</td>\n",
       "      <td>1.39</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>[CLS] where can i find the front desk [SEP]</td>\n",
       "      <td>hotel.is_there_late_check_out</td>\n",
       "      <td>hotel.where_is_the_front_desk_located</td>\n",
       "      <td>1.22</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>[CLS] may i check - out in advance [SEP]</td>\n",
       "      <td>hotel.is_there_early_check_in</td>\n",
       "      <td>hotel.is_there_late_check_out</td>\n",
       "      <td>1.22</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>[CLS] when ' s check in [SEP]</td>\n",
       "      <td>hotel.is_there_late_check_out</td>\n",
       "      <td>hotel.when_is_check_in</td>\n",
       "      <td>1.13</td>\n",
       "      <td>0.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>[CLS] check out [SEP]</td>\n",
       "      <td>hotel.is_there_early_check_in</td>\n",
       "      <td>hotel.when_is_check_out</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>[CLS] will i be charged for late check out [SEP]</td>\n",
       "      <td>hotel.is_there_late_check_out</td>\n",
       "      <td>hotel.is_there_late_check_out</td>\n",
       "      <td>1.08</td>\n",
       "      <td>0.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>[CLS] i ' ll be arriving after 11 ##pm [SEP]</td>\n",
       "      <td>hotel.is_there_late_check_out</td>\n",
       "      <td>hotel.when_is_check_in</td>\n",
       "      <td>1.02</td>\n",
       "      <td>0.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>[CLS] when can i check - in [SEP]</td>\n",
       "      <td>hotel.is_there_late_check_out</td>\n",
       "      <td>hotel.when_is_check_in</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>[CLS] map to the front desk [SEP]</td>\n",
       "      <td>hotel.is_there_late_check_out</td>\n",
       "      <td>hotel.where_is_the_front_desk_located</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>[CLS] what ' s check in time [SEP]</td>\n",
       "      <td>hotel.is_there_late_check_out</td>\n",
       "      <td>hotel.when_is_check_in</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>[CLS] when does check out finish [SEP]</td>\n",
       "      <td>hotel.when_is_check_in</td>\n",
       "      <td>hotel.when_is_check_out</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>[CLS] what is the location of the front desk [SEP]</td>\n",
       "      <td>hotel.when_is_check_in</td>\n",
       "      <td>hotel.where_is_the_front_desk_located</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>[CLS] how to do early check in [SEP]</td>\n",
       "      <td>hotel.when_is_check_in</td>\n",
       "      <td>hotel.is_there_early_check_in</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>[CLS] can i check in before 1500 [SEP]</td>\n",
       "      <td>hotel.when_is_check_in</td>\n",
       "      <td>hotel.is_there_early_check_in</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>[CLS] when does check out end [SEP]</td>\n",
       "      <td>hotel.when_is_check_in</td>\n",
       "      <td>hotel.when_is_check_out</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>[CLS] can i stay longer [SEP]</td>\n",
       "      <td>hotel.is_there_late_check_out</td>\n",
       "      <td>hotel.is_there_late_check_out</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>[CLS] please tell me where the front desk is [SEP]</td>\n",
       "      <td>hotel.when_is_check_in</td>\n",
       "      <td>hotel.where_is_the_front_desk_located</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>[CLS] is there any way to check - out late [SEP]</td>\n",
       "      <td>hotel.is_there_late_check_out</td>\n",
       "      <td>hotel.is_there_late_check_out</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "interp.show_top_losses(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Named Entity Recognition to extract parameters\n",
    "Generalizing your training data with entity classes\n",
    "Add named entities to one intent and use spaCy to extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParameterModel():\n",
    "    \n",
    "    def __init__(self, param_list):\n",
    "        self.parameters = param_list\n",
    "        self.label_ = 'PARAM'\n",
    "    \n",
    "    def replace_entities(self, text):\n",
    "        \"\"\"Replace entities in the text with their respective labels\"\"\"\n",
    "        entity_replaced_text = text\n",
    "        for p in self.parameters:\n",
    "            if p in text:\n",
    "                entity_replaced_text = text.replace(p, f'<__{self.label_}__>')\n",
    "        return entity_replaced_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_list = ['japanese','indian','thai','chinese','fast food','bbq','cafe']\n",
    "food_param_model = ParameterModel(food_list) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I want <__PARAM__>'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "food_param_model.replace_entities(\"I want fast food\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'en_core_web_sm'\n",
    "\n",
    "class SpacyModel(object):\n",
    "    spacy_model = None  # Where we keep the model when it's loaded\n",
    "\n",
    "    @classmethod\n",
    "    def get_base_spacy_model(cls):\n",
    "        \"\"\"Get the base spacy model\"\"\"\n",
    "        if not cls.spacy_model:\n",
    "            cls.spacy_model = spacy.load(MODEL_NAME)\n",
    "        return cls.spacy_model\n",
    "    \n",
    "    @classmethod\n",
    "    def replace_entities(cls, text):\n",
    "        \"\"\"Replace entities in the text with their respective labels\"\"\"\n",
    "        spacy_model = cls.get_base_spacy_model()\n",
    "        doc = spacy_model(text)\n",
    "        entity_replaced_text = text\n",
    "        for e in reversed(doc.ents):\n",
    "            start = e.start_char\n",
    "            end = start + len(e.text)\n",
    "            entity_replaced_text = entity_replaced_text[:start] + f'<__{e.label_}__>' + entity_replaced_text[end:]\n",
    "        return entity_replaced_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'how do i get to <__GPE__>'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SpacyModel.replace_entities(\"how do i get to tokyo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'can i get a reservation for <__DATE__>'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SpacyModel.replace_entities(\"can i get a reservation for Sunday\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using users to disambiguate intents\n",
    "When two intents are good candidates for the user's text, instead of picking the best, ask the user which they meant.\n",
    "Add disambiguation ability in your bot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Typos\n",
    "Since users are typing in their text, errors are common. Hence, the bot must be resilient to typos\n",
    "Add typo correction in your bot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_entities(text):\n",
    "    entity_replaced = SpacyModel.replace_entities(text)\n",
    "    entity_replaced = food_param_model.replace_entities(entity_replaced)\n",
    "    return entity_replaced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextFactory:\n",
    "\n",
    "    def __init__(self, text):\n",
    "        self.raw = text\n",
    "        self._sanitized = None\n",
    "        self._entity_replaced = None\n",
    "        self._sanitized_and_entity_replaced = None\n",
    "\n",
    "    def sanitized(self):\n",
    "        if not self._sanitized:\n",
    "            self._sanitized = preprocess(self.raw)\n",
    "        return self._sanitized\n",
    "    \n",
    "    def entity_replaced(self):\n",
    "        if not self._entity_replaced:\n",
    "            self._entity_replaced = replace_entities(self.raw)\n",
    "        return self._entity_replaced\n",
    "\n",
    "    def typo_corrected(self):\n",
    "        #if not self._typo_corrected:\n",
    "        #    self._typo_corrected = typo_correct(self.raw)\n",
    "        #return self._typo_corrected\n",
    "        pass\n",
    "\n",
    "    def sanitized_and_entity_replaced(self):\n",
    "        if not self._sanitized_and_entity_replaced:\n",
    "            self._sanitized_and_entity_replaced = replace_entities(self.sanitized())\n",
    "        return self._sanitized_and_typo_corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassifierBuilder:\n",
    "\n",
    "    def __init__(self, query):\n",
    "        self.raw_query = query\n",
    "        self.queries = []\n",
    "        self.classifiers = []\n",
    "    \n",
    "    def add_classifiers_query(self, classifier, query):\n",
    "        self.classifiers.append(classifier)\n",
    "        self.queries.append(query)\n",
    "        return self\n",
    "    \n",
    "    def build(self):\n",
    "        # validation\n",
    "        if not self.classifiers:\n",
    "            raise Exception('Must specify classifiers')\n",
    "        # build\n",
    "        preds = None\n",
    "        for c in self.classifiers:\n",
    "            pred = c.predict(self.raw_query)\n",
    "            if pred != UNK:\n",
    "                return pred\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyChatbotData:\n",
    "    \n",
    "    def __init__(self, json_obj, text_fld, answers):\n",
    "        dfs = []\n",
    "        for i, (intent, data) in enumerate(json_obj.items()):\n",
    "            # lowercase and remove punctuation\n",
    "            patterns = data[text_fld].copy()\n",
    "            for i, p in enumerate(patterns):\n",
    "                p = p.lower()\n",
    "                patterns[i] = p\n",
    "                answer = answers[intent]\n",
    "            df = pd.DataFrame(list(zip([intent]*len(patterns), patterns, [answer]*len(patterns))), \\\n",
    "                              columns=['intent', 'phrase', 'answer'])\n",
    "            dfs.append(df)\n",
    "        self.df = pd.concat(dfs)\n",
    "    \n",
    "    def get_answer(self, intent):\n",
    "        return pd.unique(self.df[self.df['intent'] == intent]['answer'])[0]\n",
    "    \n",
    "    def remove_punctuation(self, text):\n",
    "        return punct_re_escape.sub('', text)\n",
    "    \n",
    "    def get_phrases(self, intent):\n",
    "        return list(self.df[self.df['intent'] == intent]['phrase'])\n",
    "    \n",
    "    def get_intents(self):\n",
    "        return list(pd.unique(self.df['intent']))\n",
    "    \n",
    "    def show_batch(self, size=5):\n",
    "        return self.df.head(size)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExactMatch:\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def predict(self, query):\n",
    "        intents = self.data.get_intents()\n",
    "        for i in intents:\n",
    "            phrases = self.data.get_phrases(i)\n",
    "            if query in phrases:\n",
    "                return i\n",
    "        return UNK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FuzzyMatch:\n",
    "\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "    \n",
    "    def predict(self, query):\n",
    "        intents = self.data.get_intents()\n",
    "        for i in intents:\n",
    "            phrases = self.data.get_phrases(i)\n",
    "            match, score = process.extractOne(query, phrases)\n",
    "            if score > 90:\n",
    "                return chatbot_data.get_answer(i)\n",
    "        return UNK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayesMatch:\n",
    "    \n",
    "    def __init__(self, data, model):\n",
    "        self.data = data\n",
    "        self.nb_model = model\n",
    "        \n",
    "    def predict(self, query):\n",
    "        tokenized_query = tokenize_nd_join(query)\n",
    "        pred_prob = nb_model.predict_proba([tokenized_query])\n",
    "        preds_sorted = np.argsort(pred_prob)\n",
    "        top3 = preds_sorted[:,-1],preds_sorted[:,-2],preds_sorted[:,-2]\n",
    "        if pred_prob[0,top3[0]] > (pred_prob[0,top3[1]] + pred_prob[0,top3[2]]):\n",
    "            pred = nb_model.named_steps['clf'].classes_[top3[0]][0]\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistilBertMatch:\n",
    "    def __init__(self, data, learner):\n",
    "        self.data = data\n",
    "        self.learner = learner\n",
    "    \n",
    "    def predict(self, query):\n",
    "        pred, idx, probs = self.learner.predict(query)\n",
    "        return learn.data.train_ds.y.classes[pred.data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "exact_match_classifier = ExactMatch(chatbot_data)\n",
    "fuzzy_match_classifier = FuzzyMatch(chatbot_data)\n",
    "naive_bayes_classifier = NaiveBayesMatch(chatbot_data, nb_model)\n",
    "distil_bert_classifier = DistilBertMatch(chatbot_data, learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Predictor:\n",
    "    def __init__(self, query):\n",
    "        self.text_factory = TextFactory(query)\n",
    "        self.pipeline = ClassifierBuilder(query)\n",
    "\n",
    "    def predict(self):\n",
    "        pred = self.pipeline.add_classifiers_query(exact_match_classifier, self.text_factory.raw) \\\n",
    "                            .add_classifiers_query(exact_match_classifier, self.text_factory.sanitized()) \\\n",
    "                            .add_classifiers_query(exact_match_classifier, self.text_factory.entity_replaced()) \\\n",
    "                            .add_classifiers_query(distil_bert_classifier, self.text_factory.raw) \\\n",
    "                            .add_classifiers_query(distil_bert_classifier, self.text_factory.sanitized()) \\\n",
    "                            .add_classifiers_query(distil_bert_classifier, self.text_factory.entity_replaced()) \\\n",
    "                            .add_classifiers_query(fuzzy_match_classifier, self.text_factory.raw) \\\n",
    "                            .build()\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hotel.when_is_check_in'"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor = Predictor(\"what time is check-in\")\n",
    "predictor.predict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class MyChatbotData:\n",
    "    \n",
    "    def __init__(self, json_obj, text_fld):\n",
    "        xs, ys, ans = [], [], []\n",
    "        for i, (intent, data) in enumerate(json_obj.items()):\n",
    "            # lowercase and remove punctuation\n",
    "            patterns = data[text_fld].copy()\n",
    "            xs += [p.lower() for p in patterns]\n",
    "            ys += [intent]* len(patterns)\n",
    "\n",
    "        (train_x, train_y), (test_x, test_y) = MyChatbotData.make_train_test_split(xs, ys)\n",
    "        self.train_df = pd.DataFrame(np.stack((train_x, train_y),axis=1), columns=['phrase','intent'])\n",
    "        self.test_df = pd.DataFrame(np.stack((test_x, test_y),axis=1), columns=['phrase','intent'])\n",
    "    \n",
    "    @staticmethod\n",
    "    def make_train_test_split(xs, ys):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(xs, ys, test_size=0.2, random_state=42)\n",
    "        return (X_train, y_train), (X_test, y_test)\n",
    "    \n",
    "    def remove_punctuation(self, text):\n",
    "        return punct_re_escape.sub('', text)\n",
    "    \n",
    "    def get_phrases(self, intent):\n",
    "        return list(self.train_df[self.train_df['intent'] == intent]['phrase'])\n",
    "    \n",
    "    def get_intents(self):\n",
    "        return list(pd.unique(self.train_df['intent']))\n",
    "    \n",
    "    def show_batch(self, size=5):\n",
    "        return self.train_df.head(size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbot_data = MyChatbotData(training_data, 'patterns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrase</th>\n",
       "      <th>intent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>check in early</td>\n",
       "      <td>hotel.is_there_early_check_in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>required check in time</td>\n",
       "      <td>hotel.when_is_check_in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>can i late check in</td>\n",
       "      <td>hotel.when_is_check_in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>where’s the concierge</td>\n",
       "      <td>hotel.where_is_the_front_desk_located</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>what time is checkin</td>\n",
       "      <td>hotel.when_is_check_in</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   phrase                                 intent\n",
       "0          check in early          hotel.is_there_early_check_in\n",
       "1  required check in time                 hotel.when_is_check_in\n",
       "2     can i late check in                 hotel.when_is_check_in\n",
       "3   where’s the concierge  hotel.where_is_the_front_desk_located\n",
       "4    what time is checkin                 hotel.when_is_check_in"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set = chatbot_data.test_df\n",
    "test_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "exact_match_classifier = ExactMatch(chatbot_data)\n",
    "fuzzy_match_classifier = FuzzyMatch(chatbot_data)\n",
    "naive_bayes_classifier = NaiveBayesMatch(chatbot_data, nb_model)\n",
    "distil_bert_classifier = DistilBertMatch(chatbot_data, learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds, labels = [], list(test_set['intent'])\n",
    "for i in range(len(test_set)):\n",
    "    predictor = Predictor(test_set.iloc[i]['phrase'])\n",
    "    preds.append(predictor.predict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8720077220077219, 0.7837837837837838, 0.7561151245361771, None)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_recall_fscore_support(labels, preds, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
